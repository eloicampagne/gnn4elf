{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f16a31f",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c51fc546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "import yaml\n",
    "\n",
    "# TiRex\n",
    "from chronos import ChronosPipeline\n",
    "from tabpfn import TabPFNClassifier\n",
    "from tirex import load_model, ForecastModel, TiRexZero\n",
    "from tirex_util import load_tirex_from_checkpoint\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16e7168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Base class ===\n",
    "class BaseForecastModel:\n",
    "    def forecast(self, context, horizon):\n",
    "        \"\"\"Returns quantiles[1,9,horizon], mean[1,horizon]\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "# === TiRex ===\n",
    "class TiRexModel(BaseForecastModel):\n",
    "    def __init__(self, checkpoint=None):\n",
    "        if checkpoint and os.path.isfile(checkpoint):\n",
    "            self.model = load_tirex_from_checkpoint(checkpoint_path=checkpoint, model_id=\"TiRex\")\n",
    "        else:\n",
    "            self.model = load_model(\"NX-AI/TiRex\")\n",
    "\n",
    "    def forecast(self, context, horizon):\n",
    "        return self.model.forecast(context, prediction_length=horizon)\n",
    "\n",
    "\n",
    "# === Chronos ===\n",
    "class ChronosModel(BaseForecastModel):\n",
    "    def __init__(self):\n",
    "        if torch.cuda.is_available():\n",
    "            device = \"cuda\"\n",
    "        elif torch.backends.mps.is_available():\n",
    "            device = \"mps\"\n",
    "        else:\n",
    "            device = \"cpu\"\n",
    "        self.model = ChronosPipeline.from_pretrained(\"amazon/chronos-t5-base\", device_map=device)\n",
    "\n",
    "    def forecast(self, context, horizon):\n",
    "        ts = torch.tensor(context, dtype=torch.float32)\n",
    "        if ts.ndim == 1:\n",
    "            ts = ts.unsqueeze(0)\n",
    "\n",
    "        preds = self.model.predict(ts, prediction_length=horizon, num_samples=20)\n",
    "        if isinstance(preds, np.ndarray):\n",
    "            preds = torch.tensor(preds)\n",
    "        if preds.ndim == 3:\n",
    "            preds = preds.squeeze(1)\n",
    "\n",
    "        mean = preds.mean(dim=0, keepdim=True)        # shape (1, horizon)\n",
    "        quantiles = torch.quantile(\n",
    "            preds, torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]), dim=0\n",
    "        ).unsqueeze(0)                               # shape (1, 9, horizon)\n",
    "\n",
    "        return quantiles, mean\n",
    "\n",
    "# === TabPFN  ===\n",
    "class TabPFNModel(BaseForecastModel):\n",
    "    \"\"\"\n",
    "    TabPFN-based zero-shot forecaster.\n",
    "    Adapts TabPFNClassifier for time-series contexts with length and memory limits.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device=\"cpu\", max_samples=5000):\n",
    "        if torch.cuda.is_available():\n",
    "            device = \"cuda\"\n",
    "        elif torch.backends.mps.is_available():\n",
    "            device = \"mps\"\n",
    "        else:\n",
    "            device = \"cpu\"\n",
    "        self.model = TabPFNClassifier(device=device, ignore_pretraining_limits=True)\n",
    "        self.max_samples = max_samples\n",
    "\n",
    "    def forecast(self, context, horizon):\n",
    "        window = min(24, len(context))  # small receptive field\n",
    "        X = np.array([context[i - window:i] for i in range(window, len(context))])\n",
    "        y = np.array(context[window:])\n",
    "        if len(X) > self.max_samples:\n",
    "            idx = np.linspace(0, len(X) - 1, self.max_samples).astype(int)\n",
    "            X = X[idx]\n",
    "            y = y[idx]\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "        n_bins = min(9, max(2, int(len(y) / 5)))\n",
    "        bins = np.linspace(y.min(), y.max(), n_bins + 1)\n",
    "        y_disc = np.digitize(y, bins) - 1\n",
    "\n",
    "        self.model.fit(X_scaled, y_disc)\n",
    "\n",
    "        last_window = scaler.transform([context[-window:]])\n",
    "        preds = []\n",
    "        for _ in range(horizon):\n",
    "            proba = self.model.predict_proba(last_window).mean(axis=0)\n",
    "            classes = np.linspace(y.min(), y.max(), len(proba))\n",
    "            pred = float(np.dot(proba, classes))\n",
    "            preds.append(pred)\n",
    "            new_context = np.append(context, pred)[-window:]\n",
    "            last_window = scaler.transform([new_context])\n",
    "\n",
    "        preds = torch.tensor(preds).unsqueeze(0)  # (1, horizon)\n",
    "        quantiles = torch.quantile(\n",
    "            preds, torch.linspace(0.1, 0.9, 9), dim=0\n",
    "        ).unsqueeze(0)  # (1, 9, horizon)\n",
    "        return quantiles, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaee3fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df, folder_path):\n",
    "    \"\"\"Compute metrics (MAPE, RMSE), plot residuals and save results.\"\"\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    # Ensure proper typing\n",
    "    df = df.copy()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df[\"resid\"] = df[\"obs\"] - df[\"median_pred\"]\n",
    "    \n",
    "    # Metrics\n",
    "    mape_mean = np.mean(np.abs((df[\"obs\"] - df[\"median_pred\"]) / df[\"obs\"])) * 100\n",
    "    rmse_mean = np.sqrt(np.mean((df[\"obs\"] - df[\"median_pred\"])**2))\n",
    "        \n",
    "    # Plot residuals\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.lineplot(data=df, x=\"date\", y=\"resid\", color=\"steelblue\", linewidth=1.5)\n",
    "    plt.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "    plt.title(f\"Residuals over Time\\nMAPE: {mape_mean:.2f}%  |  RMSE: {rmse_mean:.0f} MW\", fontsize=13)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Residual (Observed - Predicted)\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(os.path.join(folder_path, \"residuals.png\"), dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(df[\"date\"], df[\"obs\"], label=\"Observed\", color=\"black\", linewidth=1.2)\n",
    "    plt.plot(df[\"date\"], df[\"median_pred\"], label=\"Predicted (Median)\", color=\"royalblue\", linewidth=1.2)\n",
    "    plt.fill_between(df[\"date\"], df[\"q10_pred\"], df[\"q90_pred\"], color=\"lightblue\", alpha=0.4)\n",
    "    plt.legend()\n",
    "    plt.title(\"Observed vs Predicted Consumption\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Consumption [MW]\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(folder_path, \"forecast_comparison.png\"), dpi=200)\n",
    "    plt.close()\n",
    "    print('MAPE: {:.2f}%, RMSE: {:.2f} MW'.format(mape_mean, rmse_mean))\n",
    "    return mape_mean, rmse_mean\n",
    "\n",
    "def visualize_existing_results(config_files, results_dir=\"results_tirex\", show_n=0, max_workers=4):\n",
    "    \"\"\"\n",
    "    Fast visualization of existing results.\n",
    "    - Generates forecast and residual plots for all experiments.\n",
    "    - Parallelized to speed up large batches.\n",
    "    \n",
    "    Args:\n",
    "        config_files (list[str]): list of YAML config paths.\n",
    "        results_dir (str): root folder where results are stored.\n",
    "        show_n (int): number of examples to display inline (0 = none, just save).\n",
    "        max_workers (int): number of threads for parallel plotting.\n",
    "    \"\"\"\n",
    "\n",
    "    def process_config(cfg):\n",
    "        try:\n",
    "            with open(cfg, \"r\") as file:\n",
    "                config = yaml.safe_load(file)\n",
    "            result_path = os.path.join(results_dir, config[\"expe_name\"], \"sequence.csv\")\n",
    "            out_dir = os.path.dirname(result_path)\n",
    "\n",
    "            if not os.path.exists(result_path):\n",
    "                return f\"No results for {config['expe_name']}\"\n",
    "\n",
    "            df = pd.read_csv(result_path)\n",
    "            required = {\"date\", \"obs\", \"median_pred\", \"q10_pred\", \"q90_pred\"}\n",
    "            if df.empty or not required.issubset(df.columns):\n",
    "                return f\"Invalid file for {config['expe_name']}\"\n",
    "\n",
    "            # Fast conversions\n",
    "            df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "            obs, pred = df[\"obs\"].to_numpy(), df[\"median_pred\"].to_numpy()\n",
    "            resid = obs - pred\n",
    "\n",
    "            # Metrics\n",
    "            nonzero_mask = obs != 0\n",
    "            mape = np.mean(np.abs((obs[nonzero_mask] - pred[nonzero_mask]) / obs[nonzero_mask])) * 100\n",
    "            rmse = np.sqrt(np.mean((obs - pred) ** 2))\n",
    "\n",
    "            # === Forecast plot ===\n",
    "            fig, ax = plt.subplots(figsize=(10, 4))\n",
    "            ax.plot(df[\"date\"], obs, label=\"Observation\", color=\"black\", linewidth=1)\n",
    "            ax.plot(df[\"date\"], pred, label=\"Median forecast\", color=\"royalblue\", linewidth=1)\n",
    "            ax.fill_between(df[\"date\"], df[\"q10_pred\"], df[\"q90_pred\"], color=\"lightblue\", alpha=0.4)\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"{config['expe_name']} — MAPE: {mape:.2f}% | RMSE: {rmse:.0f} MW\", fontsize=11)\n",
    "            ax.set_xlabel(\"Date\")\n",
    "            ax.set_ylabel(\"Consumption [MW]\")\n",
    "            fig.tight_layout()\n",
    "            fig.savefig(os.path.join(out_dir, \"forecast_comparison.png\"), dpi=150)\n",
    "            if show_n > 0:\n",
    "                plt.show()\n",
    "            plt.close(fig)\n",
    "\n",
    "            # === Residual plot ===\n",
    "            fig, ax = plt.subplots(figsize=(10, 3))\n",
    "            ax.plot(df[\"date\"], resid, color=\"steelblue\", linewidth=1)\n",
    "            ax.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "            ax.set_title(f\"Residuals — {config['expe_name']}\")\n",
    "            ax.set_xlabel(\"Date\")\n",
    "            ax.set_ylabel(\"Residual (Obs - Pred)\")\n",
    "            fig.tight_layout()\n",
    "            fig.savefig(os.path.join(out_dir, \"residuals.png\"), dpi=150)\n",
    "            plt.close(fig)\n",
    "\n",
    "            return f\"{config['expe_name']} done  (MAPE={mape:.2f}%, RMSE={rmse:.0f}MW)\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"{cfg}: {e}\"\n",
    "\n",
    "    # === Parallel execution ===\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(process_config, cfg): cfg for cfg in config_files}\n",
    "        for future in as_completed(futures):\n",
    "            results.append(future.result())\n",
    "\n",
    "    print(\"\\n\".join(results))\n",
    "\n",
    "def run_experiment(config_path, model_name=\"tirex\", checkpoint=None):\n",
    "    \"\"\"\n",
    "    Run forecasting for any supported foundation model (TiRex, Chronos, TabPFN).\n",
    "    Compatible with zero-shot evaluation across models.\n",
    "    \"\"\"\n",
    "    print(f\"\\nRunning {model_name.upper()} on config: {config_path}\")\n",
    "    with open(config_path, \"r\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    data = pd.read_csv(config[\"data_path\"])\n",
    "    data[\"Date_local\"] = pd.to_datetime(data[\"Date_local\"]).dt.tz_localize(None)\n",
    "    begin_train = pd.to_datetime(config[\"begin_train\"])\n",
    "    begin_test = pd.to_datetime(config[\"begin_test\"])\n",
    "    end_test = pd.to_datetime(config[\"end_test\"])\n",
    "    horizon = config[\"horizon\"]\n",
    "\n",
    "    folder_path = os.path.join(f\"results_{model_name}\", config[\"expe_name\"])\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    print(f\"Saving results to: {folder_path}\")\n",
    "\n",
    "    if model_name == \"tirex\":\n",
    "        model = TiRexModel(checkpoint)\n",
    "    elif model_name == \"chronos\":\n",
    "        model = ChronosModel()\n",
    "    elif model_name == \"tabpfn\":\n",
    "        model = TabPFNModel(device='mps', max_samples=500)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "\n",
    "    # --- Slice data ---\n",
    "    X = data[(data[\"Date_local\"] >= begin_train) & (data[\"Date_local\"] < end_test)].reset_index(drop=True)\n",
    "    y_test = X[(X[\"Date_local\"] >= begin_test) & (X[\"Date_local\"] < end_test)][\"Consommation\"].values\n",
    "    hist = X[X[\"Date_local\"] <= begin_test][\"Consommation\"].values\n",
    "    fut = X[X[\"Date_local\"] > begin_test][\"Consommation\"].values\n",
    "\n",
    "    # --- Forecast loop ---\n",
    "    quantiles_full, mean_full = [], []\n",
    "    for i in tqdm(range(0, len(y_test), horizon), desc=f\"{model_name.upper()} forecasting\"):\n",
    "        ctx = np.concatenate((hist, fut[:i]))\n",
    "        quantiles, mean = model.forecast(ctx, horizon)\n",
    "        quantiles_full.append(quantiles[0])\n",
    "        mean_full.append(mean)\n",
    "\n",
    "    m = torch.cat(mean_full, dim=1)\n",
    "    q = torch.cat(quantiles_full, dim=0)\n",
    "\n",
    "    min_len = min(m.shape[-1], len(y_test))\n",
    "    m = m[:, :min_len]\n",
    "    y_test = torch.tensor(y_test[:min_len])\n",
    "    dates_test = (\n",
    "        X.loc[(X[\"Date_local\"] >= begin_test) & (X[\"Date_local\"] < end_test), \"Date_local\"]\n",
    "        .iloc[:min_len]\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    if q.ndim == 2:\n",
    "        mean = m.clone()\n",
    "        q = torch.stack(\n",
    "            [mean * 0.9, mean * 0.95, mean * 0.97, mean * 0.99, mean,\n",
    "             mean * 1.01, mean * 1.03, mean * 1.05, mean * 1.1],\n",
    "            dim=1\n",
    "        )  # shape (1, 9, horizon)\n",
    "    else:\n",
    "        q = q[:, :, :min_len]\n",
    "\n",
    "    q10_pred = q[0, 0, :].detach().cpu()\n",
    "    median_pred = q[0, 4, :].detach().cpu()\n",
    "    q90_pred = q[0, 8, :].detach().cpu()\n",
    "\n",
    "    final = pd.DataFrame({\n",
    "        \"date\": dates_test,\n",
    "        \"obs\": y_test.numpy(),\n",
    "        \"q10_pred\": q10_pred.numpy(),\n",
    "        \"q90_pred\": q90_pred.numpy(),\n",
    "        \"median_pred\": median_pred.numpy(),\n",
    "    })\n",
    "\n",
    "    lengths = [len(final[c]) for c in final.columns]\n",
    "    assert len(set(lengths)) == 1, f\"Length mismatch detected: {lengths}\"\n",
    "\n",
    "    output_file = os.path.join(folder_path, \"sequence.csv\")\n",
    "    final.to_csv(output_file, index=False)\n",
    "    print(f\"Saved results: {output_file}\")\n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad63c0c",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de25b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_weave   = pd.read_csv('data/weave/train_weave.csv')\n",
    "train_rfrance = pd.read_csv('data/rfrance/train2.csv')\n",
    "test_weave    = pd.read_csv('data/weave/test_weave.csv')\n",
    "test_rfrance  = pd.read_csv('data/rfrance/test2.csv')\n",
    "\n",
    "df_weave   = pd.concat([train_weave, test_weave], axis=0).reset_index(drop=True)\n",
    "df_rfrance = pd.concat([train_rfrance, test_rfrance], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0b291f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Weave by site \n",
    "os.makedirs('data/weave', exist_ok=True)\n",
    "nb_ids = df_weave['id_unique'].nunique()\n",
    "pad = max(3, len(str(nb_ids)))\n",
    "\n",
    "weave_out = (\n",
    "    df_weave[['date', 'id_unique', 'consumption']]\n",
    "    .rename(columns={'date': 'Date_local', 'consumption': 'Consommation'})\n",
    "    .assign(Date_local=lambda d: pd.to_datetime(d['Date_local']))\n",
    ")\n",
    "\n",
    "for i, (_, g) in enumerate(weave_out.groupby('id_unique', sort=False), start=1):\n",
    "    g = g.sort_values('Date_local')\n",
    "    g[['Date_local', 'id_unique', 'Consommation']].to_csv(\n",
    "        f\"data/weave/{i:0{pad}d}.csv\", index=False\n",
    "    )\n",
    "\n",
    "uk = df_weave[['date','consumption']].groupby('date').sum().reset_index().sort_values('date')\n",
    "uk.columns = ['Date_local','Consommation']\n",
    "uk.to_csv('data/weave/uk.csv')\n",
    "\n",
    "# Export RFrance by region\n",
    "os.makedirs('data/rfrance', exist_ok=True)\n",
    "\n",
    "rfr_out = (\n",
    "    df_rfrance[['date', 'Region', 'load']]\n",
    "    .rename(columns={'date': 'Date_local', 'load': 'Consommation'})\n",
    "    .assign(Date_local=lambda d: pd.to_datetime(d['Date_local']))\n",
    ")\n",
    "\n",
    "for region, g in rfr_out.groupby('Region', sort=False):\n",
    "    g = g.sort_values('Date_local')\n",
    "    g[['Date_local', 'Region', 'Consommation']].to_csv(\n",
    "        f\"data/rfrance/{region[:5]}.csv\", index=False\n",
    "    )\n",
    "\n",
    "france = df_rfrance[['date','load']].groupby('date').sum().reset_index().sort_values('date')\n",
    "france.columns = ['Date_local','Consommation']\n",
    "france.to_csv('data/rfrance/france.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb13216",
   "metadata": {},
   "source": [
    "# Generate configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70d5f15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset rfrance\n",
    "data_dir = \"data/rfrance\"\n",
    "config_template = {\n",
    "    \"begin_train\": \"2015-01-01\",\n",
    "    \"begin_test\": \"2019-01-01\",\n",
    "    \"end_test\": \"2020-01-01\",\n",
    "    \"horizon\": 48\n",
    "}\n",
    "\n",
    "output_dir = \"configs/rfrance\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "csv_files = [\n",
    "    f for f in os.listdir(data_dir)\n",
    "    if f.endswith(\".csv\") and \"train\" not in f and \"test\" not in f\n",
    "]\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    region_name = os.path.splitext(csv_file)[0]  # e.g. \"Auver\"\n",
    "    config = config_template.copy()\n",
    "    config[\"expe_name\"] = f\"fm_region_{region_name}\"\n",
    "    config[\"data_path\"] = os.path.join(data_dir, csv_file)\n",
    "    output_path = os.path.join(output_dir, f\"config_rfrance_{region_name}.yaml\")\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        yaml.dump(config, f, sort_keys=False)\n",
    "\n",
    "# Dataset weave\n",
    "data_dir = \"data/weave\"\n",
    "config_template = {\n",
    "    \"begin_train\": \"2024-02-13\",\n",
    "    \"begin_test\": \"2024-02-23\",\n",
    "    \"end_test\": \"2024-02-26\",\n",
    "    \"horizon\": 48\n",
    "}\n",
    "\n",
    "output_dir = \"configs/weave\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "csv_files = [\n",
    "    f for f in os.listdir(data_dir)\n",
    "    if f.endswith(\".csv\") and \"train\" not in f and \"test\" not in f\n",
    "]\n",
    "\n",
    "for idx, csv_file in enumerate(sorted(csv_files), start=1):\n",
    "    region_name = os.path.splitext(csv_file)[0]  # e.g. \"001\"\n",
    "    config = config_template.copy()\n",
    "    config[\"expe_name\"] = f\"fm_uk_{idx}\"\n",
    "    config[\"data_path\"] = os.path.join(\"data/weave\", csv_file)\n",
    "    output_path = os.path.join(output_dir, f\"config_uk_{region_name}.yaml\")\n",
    "    with open(output_path, \"w\") as f:\n",
    "        yaml.dump(config, f, sort_keys=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4f0924",
   "metadata": {},
   "source": [
    "# Foundation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fba2b4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 config files found in configs/weave\n"
     ]
    }
   ],
   "source": [
    "DATASET = \"weave\"  # ou \"weave\"\n",
    "CONFIG_DIR = f\"configs/{DATASET}\"\n",
    "\n",
    "config_files = sorted(\n",
    "    [os.path.join(CONFIG_DIR, f) for f in os.listdir(CONFIG_DIR) if f.endswith(\".yaml\")]\n",
    ")\n",
    "print(f\"{len(config_files)} config files found in {CONFIG_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20d9a861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Benchmarking model: TIREX\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c2a128041e41b18bb939b77ce20905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TIREX:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running TIREX on config: configs/weave/config_uk_000.yaml\n",
      "Saving results to: results_tirex/fm_uk_0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6835486f9ba84a0f97a5ce00671f56c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TIREX forecasting:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results: results_tirex/fm_uk_0/sequence.csv\n",
      "TIREX already has results for fm_uk_1 → skip.\n",
      "TIREX already has results for fm_uk_2 → skip.\n",
      "TIREX already has results for fm_uk_3 → skip.\n",
      "TIREX already has results for fm_uk_4 → skip.\n",
      "TIREX already has results for fm_uk_5 → skip.\n",
      "TIREX already has results for fm_uk_6 → skip.\n",
      "TIREX already has results for fm_uk_7 → skip.\n",
      "TIREX already has results for fm_uk_8 → skip.\n",
      "TIREX already has results for fm_uk_9 → skip.\n",
      "TIREX already has results for fm_uk_10 → skip.\n",
      "TIREX already has results for fm_uk_11 → skip.\n",
      "TIREX already has results for fm_uk_12 → skip.\n",
      "TIREX already has results for fm_uk_13 → skip.\n",
      "TIREX already has results for fm_uk_14 → skip.\n",
      "TIREX already has results for fm_uk_15 → skip.\n",
      "TIREX already has results for fm_uk_16 → skip.\n",
      "TIREX already has results for fm_uk_17 → skip.\n",
      "TIREX already has results for fm_uk_18 → skip.\n",
      "TIREX already has results for fm_uk_19 → skip.\n",
      "TIREX already has results for fm_uk_20 → skip.\n",
      "TIREX already has results for fm_uk_21 → skip.\n",
      "TIREX already has results for fm_uk_22 → skip.\n",
      "TIREX already has results for fm_uk_23 → skip.\n",
      "TIREX already has results for fm_uk_24 → skip.\n",
      "TIREX already has results for fm_uk_25 → skip.\n",
      "TIREX already has results for fm_uk_26 → skip.\n",
      "TIREX already has results for fm_uk_27 → skip.\n",
      "TIREX already has results for fm_uk_28 → skip.\n",
      "TIREX already has results for fm_uk_29 → skip.\n"
     ]
    }
   ],
   "source": [
    "foundation_models = [\n",
    "    {\"name\": \"tirex\",   \"checkpoint\": None, \"model_id\": \"TiRex\"},\n",
    "    # {\"name\": \"chronos\", \"checkpoint\": None, \"model_id\": \"Chronos\"},\n",
    "    # {\"name\": \"tabpfn\",  \"checkpoint\": None, \"model_id\": \"TabPFN\"},\n",
    "]\n",
    "\n",
    "for model_info in foundation_models:\n",
    "    model_name = model_info[\"name\"]\n",
    "    checkpoint = model_info[\"checkpoint\"]\n",
    "\n",
    "    print(f\"\\nBenchmarking model: {model_name.upper()}\")\n",
    "    results_dir = f\"results_{model_name}\"\n",
    "\n",
    "    for cfg in tqdm(config_files, desc=f\"{model_name.upper()}\"):\n",
    "        try:\n",
    "            with open(cfg, \"r\") as f:\n",
    "                conf = yaml.safe_load(f)\n",
    "\n",
    "            result_path = os.path.join(results_dir, conf[\"expe_name\"], \"sequence.csv\")\n",
    "\n",
    "            if os.path.exists(result_path):\n",
    "                print(f\"{model_name.upper()} already has results for {conf['expe_name']} → skip.\")\n",
    "                continue\n",
    "\n",
    "            run_experiment(cfg, model_name=model_name, checkpoint=checkpoint)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error for {model_name.upper()} on {os.path.basename(cfg)}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7a952b",
   "metadata": {},
   "source": [
    "# Vizualisation and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93d8d54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fm_uk_3 done  (MAPE=100.83%, RMSE=596MW)\n",
      "fm_uk_4 done  (MAPE=13.98%, RMSE=1935MW)\n",
      "fm_uk_0 done  (MAPE=8.04%, RMSE=14062MW)\n",
      "fm_uk_2 done  (MAPE=40.39%, RMSE=1703MW)\n",
      "fm_uk_5 done  (MAPE=11.66%, RMSE=1212MW)\n",
      "fm_uk_1 done  (MAPE=15.21%, RMSE=1032MW)\n",
      "fm_uk_6 done  (MAPE=25.65%, RMSE=1516MW)\n",
      "fm_uk_7 done  (MAPE=28.98%, RMSE=496MW)\n",
      "fm_uk_8 done  (MAPE=32.73%, RMSE=1575MW)\n",
      "fm_uk_11 done  (MAPE=19.20%, RMSE=1433MW)\n",
      "fm_uk_9 done  (MAPE=24.94%, RMSE=1184MW)\n",
      "fm_uk_10 done  (MAPE=24.46%, RMSE=754MW)\n",
      "fm_uk_12 done  (MAPE=15.13%, RMSE=2021MW)\n",
      "fm_uk_13 done  (MAPE=18.15%, RMSE=2179MW)\n",
      "fm_uk_14 done  (MAPE=16.52%, RMSE=1467MW)\n",
      "fm_uk_15 done  (MAPE=28.93%, RMSE=1098MW)\n",
      "fm_uk_16 done  (MAPE=23.30%, RMSE=2435MW)\n",
      "fm_uk_17 done  (MAPE=19.40%, RMSE=1170MW)\n",
      "fm_uk_18 done  (MAPE=13.78%, RMSE=2101MW)\n",
      "fm_uk_19 done  (MAPE=27.77%, RMSE=1865MW)\n",
      "fm_uk_20 done  (MAPE=39.51%, RMSE=2230MW)\n",
      "fm_uk_21 done  (MAPE=39.56%, RMSE=1761MW)\n",
      "fm_uk_22 done  (MAPE=20.45%, RMSE=622MW)\n",
      "fm_uk_23 done  (MAPE=27.22%, RMSE=1252MW)\n",
      "No results for fm_uk_29\n",
      "fm_uk_24 done  (MAPE=21.59%, RMSE=1848MW)\n",
      "fm_uk_25 done  (MAPE=25.37%, RMSE=1762MW)\n",
      "fm_uk_26 done  (MAPE=25.43%, RMSE=880MW)\n",
      "fm_uk_27 done  (MAPE=20.77%, RMSE=455MW)\n",
      "fm_uk_28 done  (MAPE=23.72%, RMSE=1668MW)\n"
     ]
    }
   ],
   "source": [
    "visualize_existing_results(config_files, results_dir=\"results_chronos\", show_n=0, max_workers=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
