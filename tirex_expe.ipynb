{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f16a31f",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c51fc546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "import yaml\n",
    "\n",
    "# TiRex\n",
    "from tirex import load_model, ForecastModel, TiRexZero\n",
    "from tirex_util import load_tirex_from_checkpoint, plot_forecast, create_incrementing_folder\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaee3fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df, folder_path):\n",
    "    \"\"\"Compute metrics (MAPE, RMSE), plot residuals and save results.\"\"\"\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    # Ensure proper typing\n",
    "    df = df.copy()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df[\"resid\"] = df[\"obs\"] - df[\"median_pred\"]\n",
    "    \n",
    "    # Metrics\n",
    "    mape_mean = np.mean(np.abs((df[\"obs\"] - df[\"median_pred\"]) / df[\"obs\"])) * 100\n",
    "    rmse_mean = np.sqrt(np.mean((df[\"obs\"] - df[\"median_pred\"])**2))\n",
    "        \n",
    "    # Plot residuals\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.lineplot(data=df, x=\"date\", y=\"resid\", color=\"steelblue\", linewidth=1.5)\n",
    "    plt.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "    plt.title(f\"Residuals over Time\\nMAPE: {mape_mean:.2f}%  |  RMSE: {rmse_mean:.0f} MW\", fontsize=13)\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Residual (Observed - Predicted)\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.savefig(os.path.join(folder_path, \"residuals.png\"), dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(df[\"date\"], df[\"obs\"], label=\"Observed\", color=\"black\", linewidth=1.2)\n",
    "    plt.plot(df[\"date\"], df[\"median_pred\"], label=\"Predicted (Median)\", color=\"royalblue\", linewidth=1.2)\n",
    "    plt.fill_between(df[\"date\"], df[\"q10_pred\"], df[\"q90_pred\"], color=\"lightblue\", alpha=0.4)\n",
    "    plt.legend()\n",
    "    plt.title(\"Observed vs Predicted Consumption\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Consumption [MW]\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(folder_path, \"forecast_comparison.png\"), dpi=200)\n",
    "    plt.close()\n",
    "    print('MAPE: {:.2f}%, RMSE: {:.2f} MW'.format(mape_mean, rmse_mean))\n",
    "    return mape_mean, rmse_mean\n",
    "\n",
    "def visualize_existing_results(config_files, results_dir=\"results_tirex\", show_n=0, max_workers=4):\n",
    "    \"\"\"\n",
    "    Fast visualization of existing results.\n",
    "    - Generates forecast and residual plots for all experiments.\n",
    "    - Parallelized to speed up large batches.\n",
    "    \n",
    "    Args:\n",
    "        config_files (list[str]): list of YAML config paths.\n",
    "        results_dir (str): root folder where results are stored.\n",
    "        show_n (int): number of examples to display inline (0 = none, just save).\n",
    "        max_workers (int): number of threads for parallel plotting.\n",
    "    \"\"\"\n",
    "\n",
    "    def process_config(cfg):\n",
    "        try:\n",
    "            with open(cfg, \"r\") as file:\n",
    "                config = yaml.safe_load(file)\n",
    "            result_path = os.path.join(results_dir, config[\"expe_name\"], \"sequence.csv\")\n",
    "            out_dir = os.path.dirname(result_path)\n",
    "\n",
    "            if not os.path.exists(result_path):\n",
    "                return f\"No results for {config['expe_name']}\"\n",
    "\n",
    "            df = pd.read_csv(result_path)\n",
    "            required = {\"date\", \"obs\", \"median_pred\", \"q10_pred\", \"q90_pred\"}\n",
    "            if df.empty or not required.issubset(df.columns):\n",
    "                return f\"Invalid file for {config['expe_name']}\"\n",
    "\n",
    "            # Fast conversions\n",
    "            df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "            obs, pred = df[\"obs\"].to_numpy(), df[\"median_pred\"].to_numpy()\n",
    "            resid = obs - pred\n",
    "\n",
    "            # Metrics\n",
    "            nonzero_mask = obs != 0\n",
    "            mape = np.mean(np.abs((obs[nonzero_mask] - pred[nonzero_mask]) / obs[nonzero_mask])) * 100\n",
    "            rmse = np.sqrt(np.mean((obs - pred) ** 2))\n",
    "\n",
    "            # === Forecast plot ===\n",
    "            fig, ax = plt.subplots(figsize=(10, 4))\n",
    "            ax.plot(df[\"date\"], obs, label=\"Observation\", color=\"black\", linewidth=1)\n",
    "            ax.plot(df[\"date\"], pred, label=\"Median forecast\", color=\"royalblue\", linewidth=1)\n",
    "            ax.fill_between(df[\"date\"], df[\"q10_pred\"], df[\"q90_pred\"], color=\"lightblue\", alpha=0.4)\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"{config['expe_name']} — MAPE: {mape:.2f}% | RMSE: {rmse:.0f} MW\", fontsize=11)\n",
    "            ax.set_xlabel(\"Date\")\n",
    "            ax.set_ylabel(\"Consumption [MW]\")\n",
    "            fig.tight_layout()\n",
    "            fig.savefig(os.path.join(out_dir, \"forecast_comparison.png\"), dpi=150)\n",
    "            if show_n > 0:\n",
    "                plt.show()\n",
    "            plt.close(fig)\n",
    "\n",
    "            # === Residual plot ===\n",
    "            fig, ax = plt.subplots(figsize=(10, 3))\n",
    "            ax.plot(df[\"date\"], resid, color=\"steelblue\", linewidth=1)\n",
    "            ax.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "            ax.set_title(f\"Residuals — {config['expe_name']}\")\n",
    "            ax.set_xlabel(\"Date\")\n",
    "            ax.set_ylabel(\"Residual (Obs - Pred)\")\n",
    "            fig.tight_layout()\n",
    "            fig.savefig(os.path.join(out_dir, \"residuals.png\"), dpi=150)\n",
    "            plt.close(fig)\n",
    "\n",
    "            return f\"{config['expe_name']} done  (MAPE={mape:.2f}%, RMSE={rmse:.0f}MW)\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"{cfg}: {e}\"\n",
    "\n",
    "    # === Parallel execution ===\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(process_config, cfg): cfg for cfg in config_files}\n",
    "        for future in as_completed(futures):\n",
    "            results.append(future.result())\n",
    "\n",
    "    print(\"\\n\".join(results))\n",
    "\n",
    "def run_experiment(config_path, CHECKPOINT_FILE, MODEL_ID):\n",
    "    print(f\"\\nLoading config : {config_path}\")\n",
    "    with open(config_path, \"r\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    # Loading data\n",
    "    data = pd.read_csv(config[\"data_path\"])\n",
    "    data[\"Date_local\"] = pd.to_datetime(data[\"Date_local\"]).dt.tz_localize(None)\n",
    "\n",
    "    begin_train = pd.to_datetime(config[\"begin_train\"])\n",
    "    begin_test = pd.to_datetime(config[\"begin_test\"])\n",
    "    end_test = pd.to_datetime(config[\"end_test\"])\n",
    "    horizon = config[\"horizon\"]\n",
    "\n",
    "    folder_path = create_incrementing_folder(f\"results_tirex/{config['expe_name']}\")\n",
    "    print(f\"Results saved in dans : {folder_path}\")\n",
    "\n",
    "    X = data[(data[\"Date_local\"] >= begin_train) & (data[\"Date_local\"] < end_test)].reset_index(drop=True)\n",
    "    y_test = X[(X[\"Date_local\"] >= begin_test) & (X[\"Date_local\"] < end_test)][\"Consommation\"].values\n",
    "\n",
    "    if os.path.isfile(CHECKPOINT_FILE):\n",
    "        tirex_model = load_tirex_from_checkpoint(checkpoint_path=CHECKPOINT_FILE, model_id=MODEL_ID)\n",
    "        print(\"Model loaded from checkpoint.\")\n",
    "    else:\n",
    "        print(\"Could not find checkpoint: loading from Hugging Face.\")\n",
    "        tirex_model = load_model(\"NX-AI/TiRex\")\n",
    "\n",
    "    quantiles_full, mean_full = [], []\n",
    "    hist = X[X[\"Date_local\"] <= begin_test][\"Consommation\"].values\n",
    "    fut = X[X[\"Date_local\"] > begin_test][\"Consommation\"].values\n",
    "\n",
    "    print(f\"Lauching forecasts (horizon={horizon})...\")\n",
    "    for i in tqdm(range(0, len(y_test), horizon)):\n",
    "        ctx = np.concatenate((hist, fut[0:i]))\n",
    "        quantiles, mean = tirex_model.forecast(ctx, prediction_length=horizon)\n",
    "        mean_full.append(mean)\n",
    "        quantiles_full.append(quantiles[0])\n",
    "\n",
    "    m = torch.cat(mean_full, dim=1)\n",
    "    q = torch.cat(quantiles_full, dim=0)\n",
    "    q10_pred = torch.tensor([t[0] for t in torch.unbind(q)])\n",
    "    median_pred = torch.tensor([t[4] for t in torch.unbind(q)])\n",
    "    q90_pred = torch.tensor([t[8] for t in torch.unbind(q)])\n",
    "    y_test = torch.tensor(y_test)\n",
    "    dates_test = X[(X[\"Date_local\"] >= begin_test) & (X[\"Date_local\"] < end_test)][\"Date_local\"]\n",
    "\n",
    "    final = pd.DataFrame({\n",
    "        \"date\": dates_test,\n",
    "        \"obs\": y_test,\n",
    "        \"q10_pred\": q10_pred,\n",
    "        \"q90_pred\": q90_pred,\n",
    "        \"median_pred\": median_pred\n",
    "    })\n",
    "    output_file = os.path.join(folder_path, \"sequence.csv\")\n",
    "    final.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved : {output_file}\")\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad63c0c",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de25b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_weave   = pd.read_csv('data/weave/train_weave.csv')\n",
    "train_rfrance = pd.read_csv('data/rfrance/train2.csv')\n",
    "test_weave    = pd.read_csv('data/weave/test_weave.csv')\n",
    "test_rfrance  = pd.read_csv('data/rfrance/test2.csv')\n",
    "\n",
    "df_weave   = pd.concat([train_weave, test_weave], axis=0).reset_index(drop=True)\n",
    "df_rfrance = pd.concat([train_rfrance, test_rfrance], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0b291f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Weave by site \n",
    "os.makedirs('data/weave', exist_ok=True)\n",
    "nb_ids = df_weave['id_unique'].nunique()\n",
    "pad = max(3, len(str(nb_ids)))\n",
    "\n",
    "weave_out = (\n",
    "    df_weave[['date', 'id_unique', 'consumption']]\n",
    "    .rename(columns={'date': 'Date_local', 'consumption': 'Consommation'})\n",
    "    .assign(Date_local=lambda d: pd.to_datetime(d['Date_local']))\n",
    ")\n",
    "\n",
    "for i, (_, g) in enumerate(weave_out.groupby('id_unique', sort=False), start=1):\n",
    "    g = g.sort_values('Date_local')\n",
    "    g[['Date_local', 'id_unique', 'Consommation']].to_csv(\n",
    "        f\"data/weave/{i:0{pad}d}.csv\", index=False\n",
    "    )\n",
    "\n",
    "uk = df_weave[['date','consumption']].groupby('date').sum().reset_index().sort_values('date')\n",
    "uk.columns = ['Date_local','Consommation']\n",
    "uk.to_csv('data/weave/uk.csv')\n",
    "\n",
    "# Export RFrance by region\n",
    "os.makedirs('data/rfrance', exist_ok=True)\n",
    "\n",
    "rfr_out = (\n",
    "    df_rfrance[['date', 'Region', 'load']]\n",
    "    .rename(columns={'date': 'Date_local', 'load': 'Consommation'})\n",
    "    .assign(Date_local=lambda d: pd.to_datetime(d['Date_local']))\n",
    ")\n",
    "\n",
    "for region, g in rfr_out.groupby('Region', sort=False):\n",
    "    g = g.sort_values('Date_local')\n",
    "    g[['Date_local', 'Region', 'Consommation']].to_csv(\n",
    "        f\"data/rfrance/{region[:5]}.csv\", index=False\n",
    "    )\n",
    "\n",
    "france = df_rfrance[['date','load']].groupby('date').sum().reset_index().sort_values('date')\n",
    "france.columns = ['Date_local','Consommation']\n",
    "france.to_csv('data/rfrance/france.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb13216",
   "metadata": {},
   "source": [
    "# Generate configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70d5f15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset rfrance\n",
    "data_dir = \"data/rfrance\"\n",
    "config_template = {\n",
    "    \"begin_train\": \"2015-01-01\",\n",
    "    \"begin_test\": \"2019-01-01\",\n",
    "    \"end_test\": \"2020-01-01\",\n",
    "    \"horizon\": 48\n",
    "}\n",
    "\n",
    "output_dir = \"configs/rfrance\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "csv_files = [\n",
    "    f for f in os.listdir(data_dir)\n",
    "    if f.endswith(\".csv\") and \"train\" not in f and \"test\" not in f\n",
    "]\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    region_name = os.path.splitext(csv_file)[0]  # e.g. \"Auver\"\n",
    "    config = config_template.copy()\n",
    "    config[\"expe_name\"] = f\"fm_region_{region_name}\"\n",
    "    config[\"data_path\"] = os.path.join(data_dir, csv_file)\n",
    "    output_path = os.path.join(output_dir, f\"config_rfrance_{region_name}.yaml\")\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        yaml.dump(config, f, sort_keys=False)\n",
    "\n",
    "# Dataset weave\n",
    "data_dir = \"data/weave\"\n",
    "config_template = {\n",
    "    \"begin_train\": \"2024-02-13\",\n",
    "    \"begin_test\": \"2024-02-23\",\n",
    "    \"end_test\": \"2024-02-26\",\n",
    "    \"horizon\": 48\n",
    "}\n",
    "\n",
    "output_dir = \"configs/weave\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "csv_files = [\n",
    "    f for f in os.listdir(data_dir)\n",
    "    if f.endswith(\".csv\") and \"train\" not in f and \"test\" not in f\n",
    "]\n",
    "\n",
    "for idx, csv_file in enumerate(sorted(csv_files), start=1):\n",
    "    region_name = os.path.splitext(csv_file)[0]  # e.g. \"001\"\n",
    "    config = config_template.copy()\n",
    "    config[\"expe_name\"] = f\"fm_uk_{idx}\"\n",
    "    config[\"data_path\"] = os.path.join(\"data/weave\", csv_file)\n",
    "    output_path = os.path.join(output_dir, f\"config_uk_{region_name}.yaml\")\n",
    "    with open(output_path, \"w\") as f:\n",
    "        yaml.dump(config, f, sort_keys=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4f0924",
   "metadata": {},
   "source": [
    "# TiREX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fba2b4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 config files found in configs/rfrance\n"
     ]
    }
   ],
   "source": [
    "DATASET = \"rfrance\"  # ou \"weave\"\n",
    "CONFIG_DIR = f\"configs/{DATASET}\"\n",
    "CHECKPOINT_FILE = \"models/tirex.ckpt\"\n",
    "MODEL_ID = \"TiRex\"\n",
    "\n",
    "config_files = sorted(\n",
    "    [os.path.join(CONFIG_DIR, f) for f in os.listdir(CONFIG_DIR) if f.endswith(\".yaml\")]\n",
    ")\n",
    "print(f\"{len(config_files)} config files found in {CONFIG_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20d9a861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6273b6a6e3e24c079c11bc0e4c38d2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are already results for fm_region_Auver → skip.\n",
      "There are already results for fm_region_Bourg → skip.\n",
      "There are already results for fm_region_Breta → skip.\n",
      "There are already results for fm_region_Centr → skip.\n",
      "There are already results for fm_region_Grand → skip.\n",
      "There are already results for fm_region_Hauts → skip.\n",
      "There are already results for fm_region_Ile_d → skip.\n",
      "There are already results for fm_region_Norma → skip.\n",
      "There are already results for fm_region_Nouve → skip.\n",
      "There are already results for fm_region_Occit → skip.\n",
      "There are already results for fm_region_Pays_ → skip.\n",
      "There are already results for fm_region_Prove → skip.\n",
      "There are already results for fm_region_france → skip.\n"
     ]
    }
   ],
   "source": [
    "for cfg in tqdm(config_files):\n",
    "    try:\n",
    "        with open(cfg, \"r\") as f:\n",
    "            conf = yaml.safe_load(f)\n",
    "        result_path = os.path.join(\"results_tirex\", conf[\"expe_name\"], \"sequence.csv\")\n",
    "        if os.path.exists(result_path):\n",
    "            print(f\"There are already results for {conf['expe_name']} → skip.\")\n",
    "            continue\n",
    "        run_experiment(cfg, CHECKPOINT_FILE=CHECKPOINT_FILE, MODEL_ID=MODEL_ID)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error on {cfg}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7a952b",
   "metadata": {},
   "source": [
    "# Vizualisation and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93d8d54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fm_region_Auver done  (MAPE=3.80%, RMSE=390MW)\n",
      "fm_region_Centr done  (MAPE=5.29%, RMSE=149MW)\n",
      "fm_region_Grand done  (MAPE=4.05%, RMSE=298MW)\n",
      "fm_region_Hauts done  (MAPE=3.42%, RMSE=270MW)\n",
      "fm_region_Breta done  (MAPE=5.55%, RMSE=191MW)\n",
      "fm_region_Bourg done  (MAPE=4.80%, RMSE=153MW)\n",
      "fm_region_Ile_d done  (MAPE=4.49%, RMSE=474MW)\n",
      "fm_region_Norma done  (MAPE=3.98%, RMSE=175MW)\n",
      "fm_region_Nouve done  (MAPE=4.63%, RMSE=312MW)\n",
      "fm_region_Occit done  (MAPE=4.59%, RMSE=267MW)\n",
      "fm_region_Pays_ done  (MAPE=5.52%, RMSE=234MW)\n",
      "fm_region_Prove done  (MAPE=3.64%, RMSE=224MW)\n",
      "fm_region_france done  (MAPE=3.61%, RMSE=2648MW)\n"
     ]
    }
   ],
   "source": [
    "visualize_existing_results(config_files, results_dir=\"results_tirex\", show_n=0, max_workers=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
